---
title: PCA with R
author: Laci Cartmell
date: 11/02/2022
output:
    html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
 

## Understanding PCA

Interactions between variables are often hidden especially w/complex and/or large datasets. PCAs are often used to visualize large datasets because they reduce complexity while retaining important information. 

How do 10 variables interact with each other variable? We could make 45 pairwise scatter plots, but looking at them would be time consuming - or we could use PCA to find explore those interactions for us. 

#
#### So, what exactly is PCA?

Principal Components Analysis (PCA) is a statistical test that reduces dimensionality while preserving variance by linearly transforming data into new coordinate system with fewer dimensions than the initial data.

PCA takes in data as a dataframe. Then, it is centered and scaled which is the basis of the new coordinate plane.     
 
The transformation fits data into a coordinate system with the most variance is in the first coordinate (component), the 2nd most variance in the second coordinate, and so on. 

Each principal component is now a summary of the variables from original data. Principal components are linear combinations of the original predictors. 

Because of the orthogonal transformation the data undergoes, numerical data works the best. You could code categorical as continuous but better to use categorical variables later on for grouping (plus pretty colors)

# 
#### PCA does multiple things at once: 

- Exploratory analysis 
    - Variable reduction - we find the total variance in the original dataset explained by each principal component
    -  do our categorical variables group?
# 

- Model selection
  -  variable reduction
  -  reduce dimensionality - esp if vars are correlated
  -  PCR - Principle Component Regression

The goal of the PCA is to explain the most variability with fewer variables than we started with. If we can capture most of the variation in two dimensions, then we can project all the observations onto a scatterplot known as a biplot. However, if a majority of the variation isn't explained by the first two components, adding the 3rd pc may be necessary. But how does that change our PCA and the visualization of it?

## PCA in R

```
install.packages("ggfortify")
install.packages("devtools")
install.packages("remotes") 
install.packages("rgl")
install.packages("pca3d")
# Iris dataset - 3 species, 50 samples each
str(iris)
summary(iris)

# Create factor var w/levels for species category
group_species <- factor(iris$Species,
                       levels = c("versicolor", "virginica", "setosa"))
summary(group_species)

# Check correlation (usually done earlier)
round(cor(iris[,1:4]), 2)

# PCA
Iris_pca <- prcomp(iris[,1:4],
                   center = TRUE,   # mean of 0
                   scale. = TRUE,   # STD of 1 
                   cor=TRUE,
                   scores=TRUE)

summary(Iris_pca)
str(Iris_pca)


#Plotting a PCA - checks for linearity and normality
library(ggfortify)

#plots PC1,PC2 automatically
iris_pca_plot <- autoplot(Iris_pca,
                          data = iris,
                          #  colour = 'Species'
)
iris_pca_plot


# screeplot - how many components to keep
plot_iris_pca <- plot(Iris_pca, type="lines")


# biplot - how components were combined in 2-d
biplot_iris_pca <- biplot(Iris_pca)


```
### Review my research data script to demonstrate why need 3-dimensional plot

## PCA in 3-dimensions

The screeplot is also used to decide if our data fits a PCA. Sometimes, a PCA won't explain enough variance from only 2 components to be incredibly helpful. 



https://planspacedotorg.wordpress.com/2013/02/03/pca-3d-visualization-and-clustering-in-r/
February 3, 2013 by aaronschumacher



``` 
#####
## 3 DIMENSIONAL
library(pca3d)

pca3d(Iris_pca, group=group_species)
pca3d(Iris_pca, components = 1:3, group=group_species)

#visualize with interactive plot
snapshotPCA3d(file="first3pcs.png")

#create figure for saving
pca2d(Iris_pca, group=group_species, legend="topright")



## Alternative method

# Different pca set-up - princomp
# correlation vs. covariance matrix
Iris_pca <- princomp(iris[,1:4],
                   center = TRUE,   # mean of 0
                   scale. = TRUE,   # STD of 1 
                   cor=TRUE,
                   scores=TRUE)


library(rgl)

plot3d(Iris_pca$scores[,1:3])
text3d(Iris_pca$scores[,1:3],texts=rownames(iris))
text3d(Iris_pca$loadings[,1:3], texts=rownames(Iris_pca$loadings), col="red")
coords <- NULL
for (i in 1:nrow(Iris_pca$loadings)) {
  coords <- rbind(coords, rbind(c(0,0,0),Iris_pca$loadings[i,1:3]))
}


```

